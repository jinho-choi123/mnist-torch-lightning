{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4116edcc-1e74-4a89-b24e-b7bbcf00ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS=100\n",
    "IMG_SIZE = 28\n",
    "OUT_CLASSES = 10\n",
    "BATCH_SIZE=64\n",
    "LR = 3e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a02e6de-24f7-4beb-89ec-bf66626b6a5d",
   "metadata": {},
   "source": [
    "#### Install Dataset from https://huggingface.co/datasets/ylecun/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c039322b-3d5e-4a5a-a3d5-54083fdcaefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"ylecun/mnist\", split=\"train\")\n",
    "test_dataset = load_dataset(\"ylecun/mnist\", split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91936c37-6960-4a15-b869-ad6fb8c4ea88",
   "metadata": {},
   "source": [
    "#### Take a look at dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a859432f-0e12-4a1d-a082-a3564a5e597f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "\n",
    "sample = next(iter(train_dataset))\n",
    "image, label = sample[\"image\"], sample[\"label\"]\n",
    "pyplot.imshow(image)\n",
    "print(f\"label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a3be87-480e-4127-8fd5-0ecd89f3234a",
   "metadata": {},
   "source": [
    "#### Define collate function. Preprocess labels and images at this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bb45742-e007-4aa6-b2d0-30bf31569ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "img2tensor = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)), # resize to 28*28\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=0.5, std=0.5),\n",
    "])\n",
    "\n",
    "def train_collate_fn(samples):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for image, label in [(sample[\"image\"], sample[\"label\"]) for sample in samples]:\n",
    "        image_tensor = img2tensor(image)\n",
    "\n",
    "        images.append(image_tensor)\n",
    "        labels.append(label)\n",
    "\n",
    "    images = torch.stack(images)\n",
    "    labels = torch.tensor(labels)\n",
    "    return images, labels\n",
    "\n",
    "def test_collate_fn(samples):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for image, label in [(sample[\"image\"], sample[\"label\"]) for sample in samples]:\n",
    "        image_tensor = img2tensor(image)\n",
    "\n",
    "        images.append(image_tensor)\n",
    "        labels.append(label)\n",
    "\n",
    "    images = torch.stack(images)\n",
    "    labels = torch.tensor(labels)\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc642322-0217-4d9f-bccc-7b4f7c125e5d",
   "metadata": {},
   "source": [
    "#### Define MNIST Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d9fbfe-7460-4943-a6d8-2ccc8fab784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "class Mnist_Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels = 32, kernel_size=3, padding=\"same\")\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=\"same\")\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 14 * 14, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 10)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.activation(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b07a82b-6635-4b85-a0d7-367b61be96e2",
   "metadata": {},
   "source": [
    "#### Test the model using torchinfo.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "100f2969-a28e-4b76-ac4d-5df620dac743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Mnist_Classifier                         [64, 10]                  --\n",
       "├─Conv2d: 1-1                            [64, 32, 28, 28]          320\n",
       "├─ReLU: 1-2                              [64, 32, 28, 28]          --\n",
       "├─Conv2d: 1-3                            [64, 64, 28, 28]          18,496\n",
       "├─ReLU: 1-4                              [64, 64, 28, 28]          --\n",
       "├─MaxPool2d: 1-5                         [64, 64, 14, 14]          --\n",
       "├─Flatten: 1-6                           [64, 12544]               --\n",
       "├─Linear: 1-7                            [64, 4096]                51,384,320\n",
       "├─ReLU: 1-8                              [64, 4096]                --\n",
       "├─Linear: 1-9                            [64, 1024]                4,195,328\n",
       "├─ReLU: 1-10                             [64, 1024]                --\n",
       "├─Linear: 1-11                           [64, 10]                  10,250\n",
       "├─LogSoftmax: 1-12                       [64, 10]                  --\n",
       "==========================================================================================\n",
       "Total params: 55,608,714\n",
       "Trainable params: 55,608,714\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 4.50\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 41.16\n",
       "Params size (MB): 222.43\n",
       "Estimated Total Size (MB): 263.80\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "model = Mnist_Classifier()\n",
    "summary(model, input_size=(BATCH_SIZE, 1, IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0e90a1-1fae-4306-b141-7a6d9f69b79b",
   "metadata": {},
   "source": [
    "#### Define lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d9150cd-465b-4bc2-bddb-75fd1bfb04b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np \n",
    "\n",
    "class Lit_Mnist_Classifier(L.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = LR\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.criterion = nn.NLLLoss()\n",
    "\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_total = 0\n",
    "        self.val_correct = 0\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self.model(images)\n",
    "\n",
    "        train_loss = self.criterion(outputs, labels)\n",
    "        self.train_losses.append(train_loss.item())\n",
    "\n",
    "        return train_loss\n",
    "    def on_train_epoch_end(self):\n",
    "        # print the average train_loss \n",
    "        print(f\"Average Training Loss in EPOCH #{self.current_epoch}: {np.mean(self.train_losses)}\")\n",
    "        self.train_losses = []\n",
    "        return\n",
    "        \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self.model(images)\n",
    "\n",
    "        val_loss = self.criterion(outputs, labels)\n",
    "\n",
    "        # get the validation accuracy\n",
    "        _, predictions = torch.max(outputs, dim=-1)\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                self.val_total += 1\n",
    "                self.val_correct += 1\n",
    "            else:\n",
    "                self.val_total += 1\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # print the average val_loss \n",
    "        print(f\"Average Validation Loss in EPOCH #{self.current_epoch}: {np.mean(self.val_losses)}\")\n",
    "        \n",
    "        # print the validation accuracy\n",
    "        print(f\"Validation Accuracy in EPOCH #{self.current_epoch}: {self.val_correct / self.val_total * 100:.2f}%\")\n",
    "        self.val_losses = []\n",
    "        self.val_correct = 0\n",
    "        self.val_total = 0\n",
    "        return\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(train_dataset, shuffle=True, collate_fn=train_collate_fn, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(test_dataset, shuffle=False, collate_fn=test_collate_fn, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ef5393-30ad-49b4-aff9-7bf7476a26ec",
   "metadata": {},
   "source": [
    "#### Train with Lightning Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f801d82-3165-4c3e-a29c-3ba7768616a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 3/99 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━╸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━</span> 529/938 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:44 • 0:00:35</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">12.00it/s</span> <span style=\"font-style: italic\">v_num: 9.000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Epoch 3/99 \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;98;6;224m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m 529/938 \u001b[2m0:00:44 • 0:00:35\u001b[0m \u001b[2;4m12.00it/s\u001b[0m \u001b[3mv_num: 9.000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x1059c1790>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:575\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    569\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    571\u001b[0m     ckpt_path,\n\u001b[1;32m    572\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:982\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 982\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1026\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py:293\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    292\u001b[0m     batch \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39m_on_before_batch_transfer(batch, dataloader_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 293\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_to_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_ready()\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:323\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 323\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:278\u001b[0m, in \u001b[0;36mStrategy.batch_to_device\u001b[0;34m(self, batch, device, dataloader_idx)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_batch_transfer_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m move_data_to_device(batch, device)\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py:352\u001b[0m, in \u001b[0;36mLightningModule._apply_batch_transfer_handler\u001b[0;34m(self, batch, device, dataloader_idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m device \u001b[38;5;241m=\u001b[39m device \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 352\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransfer_batch_to_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_hook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_after_batch_transfer\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch, dataloader_idx)\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py:341\u001b[0m, in \u001b[0;36mLightningModule._call_batch_hook\u001b[0;34m(self, hook_name, *args)\u001b[0m\n\u001b[1;32m    339\u001b[0m         trainer_method \u001b[38;5;241m=\u001b[39m call\u001b[38;5;241m.\u001b[39m_call_lightning_datamodule_hook\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, hook_name)\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:171\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 171\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning/pytorch/core/hooks.py:611\u001b[0m, in \u001b[0;36mDataHooks.transfer_batch_to_device\u001b[0;34m(self, batch, device, dataloader_idx)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Override this hook if your :class:`~torch.utils.data.DataLoader` returns tensors wrapped in a custom data\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;124;03mstructure.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    609\u001b[0m \n\u001b[1;32m    610\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmove_data_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning/fabric/utilities/apply_func.py:110\u001b[0m, in \u001b[0;36mmove_data_to_device\u001b[0;34m(batch, device)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_to_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_TransferableDataType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_to\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning_utilities/core/apply_func.py:68\u001b[0m, in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data):  \u001b[38;5;66;03m# 1d homogeneous tuple\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(function(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mdict\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mvalues()):  \u001b[38;5;66;03m# 1d homogeneous dict\u001b[39;00m\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning_utilities/core/apply_func.py:68\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data):  \u001b[38;5;66;03m# 1d homogeneous tuple\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mdict\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mvalues()):  \u001b[38;5;66;03m# 1d homogeneous dict\u001b[39;00m\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning/fabric/utilities/apply_func.py:104\u001b[0m, in \u001b[0;36mmove_data_to_device.<locals>.batch_to\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    103\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon_blocking\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m data_output \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m      3\u001b[0m lit_model \u001b[38;5;241m=\u001b[39m Lit_Mnist_Classifier(model)\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m      6\u001b[0m     val_check_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m      7\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39mMAX_EPOCHS, \n\u001b[1;32m      8\u001b[0m     num_sanity_val_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      9\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[RichProgressBar()],\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlit_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:539\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/workspace/projects/mnist-torch-lightning/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.callbacks import RichProgressBar\n",
    "\n",
    "lit_model = Lit_Mnist_Classifier(model)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    val_check_interval=1.0,\n",
    "    max_epochs=MAX_EPOCHS, \n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[RichProgressBar()],\n",
    ")\n",
    "\n",
    "trainer.fit(lit_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2517980d-a177-430c-8ea3-dec00b2d5b0b",
   "metadata": {},
   "source": [
    "#### Let's predict the number in the image using the trained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60c59041-c9c1-4e3a-b22e-1fee751dced2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicted the image's number as 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_path = \"./images/example.jpg\"\n",
    "image = Image.open(img_path)\n",
    "pyplot.imshow(image)\n",
    "\n",
    "# convert the image to tensor \n",
    "image = img2tensor(image)\n",
    "\n",
    "# since model gets images as batch, just exend the dim 0 \n",
    "image = image.unsqueeze(0)\n",
    "\n",
    "outputs = model(image)\n",
    "\n",
    "_, predictions = torch.max(outputs, dim=-1)\n",
    "\n",
    "prediction = predictions[0]\n",
    "print(f\"Model predicted the image's number as {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b57ee5-f84b-4ea8-965e-f233ff23fc11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
